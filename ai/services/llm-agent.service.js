const {
  getGeminiClient,
  isGeminiConfigured,
  GEMINI_MODEL,
} = require("./genai-client");
const { SYSTEM_PROMPT, VOICE_SYSTEM_PROMPT } = require("../system-prompt");

const MAX_RETRIES = 5; // Increased from 2 to 5
const BASE_RETRY_DELAY = 1000; // Start with 1 second
const MAX_RETRY_DELAY = 16000; // Max 16 seconds
const MAX_HISTORY_MESSAGES = 8;

// Sleep helper with exponential backoff
const sleep = (ms) => new Promise(resolve => setTimeout(resolve, ms));

// Calculate exponential backoff delay
const getRetryDelay = (attempt) => {
  // Exponential backoff: 1s, 2s, 4s, 8s, 16s
  const delay = Math.min(BASE_RETRY_DELAY * Math.pow(2, attempt - 1), MAX_RETRY_DELAY);
  // Add random jitter (0-20%) to avoid thundering herd
  const jitter = delay * 0.2 * Math.random();
  return Math.floor(delay + jitter);
};

/**
 * ØªØ­ÙˆÙŠÙ„ Ø­Ø§Ù„Ø© Ø§Ù„Ø¹Ù‚Ø§Ø± Ù„Ù†Øµ Ø¹Ø±Ø¨ÙŠ ÙˆØ§Ø¶Ø­
 */
function getAvailabilityStatus(status) {
  const statusMap = {
    available: "âœ… Ù…ØªØ§Ø­ Ù„Ù„Ø¨ÙŠØ¹/Ø§Ù„Ø¥ÙŠØ¬Ø§Ø±",
    sold: "âŒ ØªÙ… Ø¨ÙŠØ¹Ù‡ - ØºÙŠØ± Ù…ØªØ§Ø­",
    rented: "âŒ ØªÙ… ØªØ£Ø¬ÙŠØ±Ù‡ - ØºÙŠØ± Ù…ØªØ§Ø­",
    "under-construction": "ğŸ—ï¸ ØªØ­Øª Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡ - Ù…ØªØ§Ø­ Ù„Ù„Ø­Ø¬Ø²",
    completed: "âœ… Ù…ÙƒØªÙ…Ù„ - Ù…ØªØ§Ø­",
    planned: "ğŸ“‹ Ù…Ø®Ø·Ø· - Ù‚Ø±ÙŠØ¨Ø§Ù‹",
  };
  return statusMap[status] || "âœ… Ù…ØªØ§Ø­";
}

/**
 * Generate AI response using OpenAI chat completions (defaults to gpt-4o-mini)
 * @param {String} userQuery - User's question
 * @param {Array} retrievedProperties - Properties from vector search
 * @returns {Promise<String>} AI-generated response in Arabic
 */
const toPlainText = (value) => {
  if (!value) return "";
  if (typeof value === "string") return value;
  if (typeof value === "number") return value.toString();
  return "";
};

const formatConversationHistory = (history = []) => {
  if (!Array.isArray(history) || history.length === 0) {
    return "";
  }

  return history
    .slice(-MAX_HISTORY_MESSAGES)
    .map((message, index) => {
      if (!message) return null;
      const role = message.role === "assistant" ? "Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯" : "Ø§Ù„Ø¹Ù…ÙŠÙ„";
      const content = toPlainText(message.content || message.text).trim();
      if (!content) return null;
      return `${index + 1}. ${role}: ${content}`;
    })
    .filter(Boolean)
    .join("\n");
};

/**
 * Generate AI response using Google Gemini
 * @param {String} userQuery - User's question
 * @param {Array} retrievedProperties - Properties from vector search
 * @param {Array} conversationHistory - Previous conversation turns [{ role: 'user'|'assistant', content: '...' }]
 * @param {String} memorySummary - Summary of previous conversations from memory
 * @param {String} negotiationsContext - Context about user's active negotiations
 * @returns {Promise<String>} AI-generated response in Arabic
 */
async function generateAIResponse(userQuery, retrievedProperties, conversationHistory = [], memorySummary = "", negotiationsContext = "") {
  let lastError;
  
  for (let attempt = 1; attempt <= MAX_RETRIES; attempt++) {
    try {
      console.log(`\nğŸ”§ === Gemini Generation Attempt ${attempt}/${MAX_RETRIES} ===`);
      const historyContext = formatConversationHistory(conversationHistory);
      
      // Format properties data for the AI - COMPACT VERSION
      const propertiesContext = retrievedProperties
        .map((prop, index) => {
          const status = getAvailabilityStatus(prop.status);
          const price = prop.price ? prop.price.toLocaleString() : "â€”";
          const city = prop.location?.city || "";
          const area = prop.location?.area || "";
          const location = [city, area].filter(Boolean).join("-");
          
          return `${index + 1}. **${prop.title || "Ø¹Ù‚Ø§Ø±"}** | ${price} Ø¬ | ${location} | ${prop.bedrooms || 0}Øº ${prop.bathrooms || 0}Ø­ | ${prop.area || "â€”"}Ù…Â² | ${status}`;
        })
        .join("\n");

      const contextMessage =
        retrievedProperties.length > 0
          ? `Ø§Ù„Ø¹Ù‚Ø§Ø±Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©:\n${propertiesContext}\n\nØ±Ø¯ Ø¹Ù„Ù‰ Ø³Ø¤Ø§Ù„ Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ù‚Ø§Ø±Ø§Øª Ø¯ÙŠ.`
          : `Ù…ÙÙŠØ´ Ø¹Ù‚Ø§Ø±Ø§Øª Ù…Ø·Ø§Ø¨Ù‚Ø©. Ø§Ø¹ØªØ°Ø± ÙˆØ§Ù‚ØªØ±Ø­ ØªÙˆØ³ÙŠØ¹ Ø§Ù„Ø¨Ø­Ø«.`;

      // Get Gemini client
      console.log("ğŸ”‘ Initializing Gemini client...");
      const client = getGeminiClient();
      if (!client) {
        throw new Error("Google AI not configured - missing API key");
      }
      console.log("âœ… Gemini client initialized");
      
      // Combine system prompt with context and user query - COMPACT
      const conversationContext = historyContext ? `ğŸ“œ Ø³ÙŠØ§Ù‚:\n${historyContext}\n` : "";
      const memoryContext = memorySummary ? `ğŸ§  Ø°Ø§ÙƒØ±Ø©:\n${memorySummary}\n` : "";
      const negotiationsInfo = negotiationsContext ? `ğŸ’¼ ØªÙØ§ÙˆØ¶Ø§Øª:\n${negotiationsContext}\n` : "";

      const fullPrompt = `${SYSTEM_PROMPT}\n${memoryContext}${negotiationsInfo}${conversationContext}${contextMessage}\n\nâ“ ${userQuery}`;
      
      console.log(`ğŸ“ Prompt prepared (${fullPrompt.length} chars, ${retrievedProperties.length} properties)`);
      console.log(`ğŸ¤– Calling model: ${GEMINI_MODEL}`);
      console.log("ğŸ“¤ Sending request to Gemini API...");
      
      const response = await client.models.generateContent({
        model: GEMINI_MODEL,
        contents: fullPrompt,
        temperature: 0, // Adjust for more creative responses if needed
      });
      
      console.log("ğŸ“¥ Received response from Gemini");
      
      const aiResponse = response.text;
      console.log(`âœ… Response text extracted (${aiResponse.length} chars)`);

      if (!aiResponse || aiResponse.trim().length === 0) {
        throw new Error("Empty response from Gemini");
      }

      console.log("âœ… AI response generated successfully (Gemini)\n");
      return aiResponse;
      
    } catch (error) {
      lastError = error;
      
      console.error(`\nâŒ === Error in Attempt ${attempt}/${MAX_RETRIES} ===`);
      console.error(`Error Type: ${error.constructor.name}`);
      console.error(`Error Message: ${error.message}`);
      if (error.stack) {
        console.error(`Stack Trace: ${error.stack.split('\n').slice(0, 3).join('\n')}`);
      }
      
      const isRateLimitError = error.message?.includes("429") || error.message?.includes("quota");
      const isServerError = error.message?.includes("503") || error.message?.includes("500") || error.message?.includes("overloaded");
      const is404Error = error.message?.includes("404");
      const isNetworkError = error.message?.includes("ECONNREFUSED") || error.message?.includes("ETIMEDOUT");
      
      const shouldRetry = (isRateLimitError || isServerError || isNetworkError) && attempt < MAX_RETRIES;
      
      if (is404Error) {
        console.error(`ğŸ”´ Model "${GEMINI_MODEL}" not found. Check available models.`);
      } else if (isRateLimitError) {
        console.error(`âš ï¸  Rate limit (429) - Will retry with backoff`);
      } else if (isServerError) {
        console.error(`âš ï¸  Server overloaded (503) - Will retry with backoff`);
      } else if (isNetworkError) {
        console.error(`âš ï¸  Network error - Will retry with backoff`);
      } else {
        console.error(`âš ï¸  Unknown error - ${shouldRetry ? 'Will retry' : 'Will not retry'}`);
      }
      
      if (shouldRetry) {
        const delayMs = getRetryDelay(attempt);
        console.log(`â³ Exponential backoff: Retrying in ${(delayMs / 1000).toFixed(1)}s... (attempt ${attempt}/${MAX_RETRIES})`);
        await sleep(delayMs);
      } else {
        console.log(`âŒ Not retrying - attempt ${attempt}/${MAX_RETRIES} failed with non-retryable error`);
        break;
      }
    }
  }
  
  console.error("\nâŒ === All Retry Attempts Failed ===");
  console.error(`Final Error: ${lastError?.message || 'Unknown error'}\n`);
  
  // Fallback response when AI is unavailable
  if (lastError?.message?.includes("503") || lastError?.message?.includes("overloaded")) {
    console.log("âš ï¸ Returning fallback response due to API overload");
    if (retrievedProperties && retrievedProperties.length > 0) {
      const prop = retrievedProperties[0];
      return `Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø§Ù„Ù†Ø¸Ø§Ù… Ù…Ø´ØºÙˆÙ„ Ø­Ø§Ù„ÙŠØ§Ù‹. Ù„ÙƒÙ† Ù„Ù‚ÙŠØª Ù„Ø­Ø¶Ø±ØªÙƒ **${prop.title || 'Ø¹Ù‚Ø§Ø±'}** ÙÙŠ ${prop.location?.city || ''} Ø¨Ø³Ø¹Ø± ${prop.price?.toLocaleString() || 'â€”'} Ø¬Ù†ÙŠÙ‡. Ø¬Ø±Ø¨ ØªØ§Ù†ÙŠ Ø¨Ø¹Ø¯ Ø´ÙˆÙŠØ©! ğŸ™`;
    }
    return "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø§Ù„Ù†Ø¸Ø§Ù… Ù…Ø´ØºÙˆÙ„ Ø­Ø§Ù„ÙŠØ§Ù‹. Ù…Ù† ÙØ¶Ù„Ùƒ Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© ØªØ§Ù†ÙŠØ© Ø¨Ø¹Ø¯ Ø¯Ù‚ÙŠÙ‚Ø©. ğŸ™";
  }
  
  throw lastError;
}

/**
 * Generate a follow-up question based on context
 * @param {String} previousQuery - User's previous question
 * @param {String} aiResponse - Previous AI response
 * @returns {Promise<String>} Suggested follow-up question
 */
async function generateFollowUpQuestion(previousQuery, aiResponse) {
  try {
    const client = getGeminiClient();
    if (!client) {
      return null;
    }
    
    const prompt = `Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ. Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ø³Ø¤Ø§Ù„ Ù…ØªØ§Ø¨Ø¹Ø© Ù…ÙÙŠØ¯ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©.

Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø³Ø§Ø¨Ù‚: ${previousQuery}
Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©: ${aiResponse}

Ø§Ù‚ØªØ±Ø­ Ø³Ø¤Ø§Ù„ Ù…ØªØ§Ø¨Ø¹Ø© ÙˆØ§Ø­Ø¯ Ø°ÙƒÙŠ ÙŠØ³Ø§Ø¹Ø¯ Ø§Ù„Ø¹Ù…ÙŠÙ„ ÙÙŠ Ø§ØªØ®Ø§Ø° Ù‚Ø±Ø§Ø± Ø£ÙØ¶Ù„ (Ø¬Ù…Ù„Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø·).`;
    
    const response = await client.models.generateContent({
      model: GEMINI_MODEL,
      contents: prompt,
    });
    
    return response.text;
    
  } catch (error) {
    console.error("âŒ Error generating follow-up question:", error.message);
    return null;
  }
}

/**
 * ğŸ¤ Generate Voice-Optimized AI Response
 * Optimized for text-to-speech output - shorter, clearer, no emojis
 * @param {String} userSpeechText - Text from speech recognition
 * @param {Array} retrievedUnits - Properties from database
 * @param {String} currentStage - discovery | recommendation | negotiation | booking | contract
 * @param {Array} conversationHistory - Previous conversation turns
 * @param {String} memorySummary - Summary of previous conversations
 * @param {String} negotiationsContext - Context about user's active negotiations
 * @returns {Promise<String>} Voice-optimized AI response
 */
async function generateVoiceResponse(userSpeechText, retrievedUnits = [], currentStage = "discovery", conversationHistory = [], memorySummary = "", negotiationsContext = "") {
  let lastError;
  
  for (let attempt = 1; attempt <= MAX_RETRIES; attempt++) {
    try {
      console.log(`\nğŸ¤ === Voice Response Attempt ${attempt}/${MAX_RETRIES} ===`);
      console.log(`ğŸ“ Stage: ${currentStage}`);
      
      const historyContext = formatConversationHistory(conversationHistory);
      
      // Format properties for voice - VERY COMPACT, no special characters
      const unitsContext = retrievedUnits.length > 0
        ? retrievedUnits.slice(0, 2).map((prop, index) => {
            const price = prop.price ? prop.price.toLocaleString() : "ØºÙŠØ± Ù…Ø­Ø¯Ø¯";
            const city = prop.location?.city || "";
            const area = prop.area || "ØºÙŠØ± Ù…Ø­Ø¯Ø¯";
            return `${index + 1}. ${prop.title || "Ø¹Ù‚Ø§Ø±"} ÙÙŠ ${city}ØŒ ${area} Ù…ØªØ±ØŒ Ø¨Ø³Ø¹Ø± ${price} Ø¬Ù†ÙŠÙ‡`;
          }).join(". ")
        : "Ù„Ø§ ØªÙˆØ¬Ø¯ ÙˆØ­Ø¯Ø§Øª Ù…ØªØ§Ø­Ø© Ø­Ø§Ù„ÙŠØ§Ù‹";

      // Get Gemini client
      const client = getGeminiClient();
      if (!client) {
        throw new Error("Google AI not configured - missing API key");
      }
      
      // Build voice-optimized prompt
      const stageContext = `Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©: ${currentStage}`;
      const conversationContext = historyContext ? `Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©:\n${historyContext}\n` : "";
      const memoryContext = memorySummary ? `Ø°Ø§ÙƒØ±Ø© Ø³Ø§Ø¨Ù‚Ø©:\n${memorySummary}\n` : "";
      const negotiationsInfo = negotiationsContext ? `ØªÙØ§ÙˆØ¶Ø§Øª:\n${negotiationsContext}\n` : "";

      const fullPrompt = `${VOICE_SYSTEM_PROMPT}

${stageContext}
${memoryContext}${negotiationsInfo}${conversationContext}
Ø§Ù„ÙˆØ­Ø¯Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©: ${unitsContext}

ÙƒÙ„Ø§Ù… Ø§Ù„Ø¹Ù…ÙŠÙ„: ${userSpeechText}

Ø±Ø¯ Ø¨ØµÙˆØª ÙˆØ§Ø¶Ø­ ÙˆÙ…Ø®ØªØµØ±:`;
      
      console.log(`ğŸ“ Voice prompt prepared (${fullPrompt.length} chars)`);
      
      const response = await client.models.generateContent({
        model: GEMINI_MODEL,
        contents: fullPrompt,
        config: {
          temperature: 0.3, // Slightly creative but consistent
          maxOutputTokens: 300, // Keep responses short for voice
        }
      });
      
      let voiceResponse = response.text;
      
      // Clean up response for voice (remove emojis and special characters)
      voiceResponse = voiceResponse
        .replace(/[\u{1F300}-\u{1F9FF}]/gu, '') // Remove emojis
        .replace(/[âœ…âŒâš ï¸ğŸ ğŸ’°ğŸ“‹ğŸ‰â³ğŸ¤”ğŸ˜ŠğŸ‘ğŸ¤©ğŸ“ŠğŸ“ğŸ”âœ”ï¸âœ–ï¸]/g, '') // Remove specific emojis
        .replace(/\*\*/g, '') // Remove bold markdown
        .replace(/\*/g, '') // Remove italics
        .replace(/#+\s*/g, '') // Remove headers
        .replace(/\n{3,}/g, '\n\n') // Reduce multiple newlines
        .trim();
      
      if (!voiceResponse || voiceResponse.trim().length === 0) {
        throw new Error("Empty voice response from Gemini");
      }

      console.log(`âœ… Voice response generated (${voiceResponse.length} chars)\n`);
      return voiceResponse;
      
    } catch (error) {
      lastError = error;
      console.error(`âŒ Voice attempt ${attempt} failed: ${error.message}`);
      
      const isRateLimitError = error.message?.includes("429");
      const isServerError = error.message?.includes("503") || error.message?.includes("500");
      
      if ((isRateLimitError || isServerError) && attempt < MAX_RETRIES) {
        const delayMs = getRetryDelay(attempt);
        console.log(`â³ Retrying in ${(delayMs / 1000).toFixed(1)}s...`);
        await sleep(delayMs);
      } else {
        break;
      }
    }
  }
  
  // Fallback voice response
  console.error(`âŒ Voice generation failed: ${lastError?.message}`);
  if (retrievedUnits && retrievedUnits.length > 0) {
    const prop = retrievedUnits[0];
    return `Ù…Ø¹Ù„Ø´ØŒ Ø­ØµÙ„ Ù…Ø´ÙƒÙ„Ø© ØªÙ‚Ù†ÙŠØ©. Ù„ÙƒÙ† Ø¹Ù†Ø¯ÙŠ ${prop.title || 'Ø¹Ù‚Ø§Ø±'} ÙÙŠ ${prop.location?.city || 'Ù…ÙˆÙ‚Ø¹ Ù…Ù…ÙŠØ²'} Ù…Ù…ÙƒÙ† ÙŠÙ†Ø§Ø³Ø¨Ùƒ. ØªØ­Ø¨ Ø£ÙƒÙ…Ù„ Ù…Ø¹Ø§ÙƒØŸ`;
  }
  return "Ù…Ø¹Ù„Ø´ØŒ Ø­ØµÙ„ Ù…Ø´ÙƒÙ„Ø© ØªÙ‚Ù†ÙŠØ© Ø¨Ø³ÙŠØ·Ø©. Ù…Ù…ÙƒÙ† ØªØ¹ÙŠØ¯ Ø§Ù„Ø³Ø¤Ø§Ù„ ØªØ§Ù†ÙŠØŸ";
}

module.exports = {
  generateAIResponse,
  generateVoiceResponse,
  generateFollowUpQuestion,
  isGeminiConfigured,
  VOICE_SYSTEM_PROMPT,
};
