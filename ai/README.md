# ğŸ¤– AI Module - RAG + LLM for Real Estate

Complete production-ready AI module with Retrieval-Augmented Generation (RAG) using OpenAI.

---

## ğŸ“ Folder Structure

```
/ai
â”œâ”€â”€ /services
â”‚   â”œâ”€â”€ embeddings.service.js       # Generate & manage embeddings
â”‚   â”œâ”€â”€ vector-search.service.js    # MongoDB vector search
â”‚   â””â”€â”€ llm-agent.service.js        # OpenAI responses (default gpt-4o-mini)
â”œâ”€â”€ /controllers
â”‚   â””â”€â”€ ai.controller.js            # API request handlers
â”œâ”€â”€ /routes
â”‚   â””â”€â”€ ai.routes.js                # Express routes
â”œâ”€â”€ system-prompt.js                # Arabic system prompt for AI
â”œâ”€â”€ index.js                        # Module exports
â””â”€â”€ README.md                       # This file
```

---

## ğŸš€ Installation & Setup

### 1ï¸âƒ£ Install Required Packages

```bash
npm install openai
```

### 2ï¸âƒ£ Add Environment Variables

Add to your `.env` file:

```env
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_COMPLETION_MODEL=gpt-4o-mini # optional override (defaults to this value)
```

> Note: The AI module now uses `gpt-4o-mini` by default because it balances quality and latency for Arabic real-estate queries. Set `OPENAI_COMPLETION_MODEL` if you prefer a different OpenAI chat model (for example `gpt-4o` or `gpt-4.1`).

### 3ï¸âƒ£ Update Property Model

Add `embedding` field to your `propertyModel.js`:

```javascript
const propertySchema = new mongoose.Schema({
  // ... existing fields ...
  
  embedding: {
    type: [Number],
    select: false, // Don't include in regular queries
  },
});
```

### 4ï¸âƒ£ Integrate Routes into Main Server

In your `server/index.js`, add:

```javascript
const aiRoutes = require("./ai/routes/ai.routes");

// ... other routes ...

app.use("/api/ai", aiRoutes);
```

---

## ğŸ”§ MongoDB Atlas Vector Search Setup

### Step 1: Create Vector Search Index

1. Go to **MongoDB Atlas** â†’ Your Cluster â†’ **Search**
2. Click **"Create Search Index"**
3. Choose **"JSON Editor"**
4. Paste this configuration:

```json
{
  "fields": [
    {
      "type": "vector",
      "path": "embedding",
      "numDimensions": 3072,
      "similarity": "cosine"
    },
    {
      "type": "filter",
      "path": "price"
    },
    {
      "type": "filter",
      "path": "type"
    },
    {
      "type": "filter",
      "path": "bedrooms"
    },
    {
      "type": "filter",
      "path": "location.city"
    }
  ]
}
```

5. **Index Name:** `property_vector_index`
6. **Database:** Your database name
7. **Collection:** `properties`
8. Click **"Create Search Index"**
9. â³ Wait 2-5 minutes for index to build

---

## ğŸ“¡ API Endpoints

### 1. AI Query (Main Endpoint)

**POST** `/api/ai/query`

**Headers:**
```
Authorization: Bearer <your-jwt-token>
```

**Body:**
```json
{
  "query": "Ø§Ø¨Ø­Ø« Ø¹Ù† Ø´Ù‚Ø© ÙÙŠ Ø¯Ø¨ÙŠ Ù…Ø§Ø±ÙŠÙ†Ø§ Ø¨Ø³Ø¹Ø± Ø£Ù‚Ù„ Ù…Ù† 2 Ù…Ù„ÙŠÙˆÙ† Ø¯Ø±Ù‡Ù…",
  "filters": {
    "maxPrice": 2000000,
    "type": "apartment",
    "city": "Dubai"
  }
}
```

**Response:**
```json
{
  "success": true,
  "answer": "Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¨Ø­Ø«Ùƒ Ø¹Ù† Ø´Ù‚Ø© ÙÙŠ Ø¯Ø¨ÙŠ Ù…Ø§Ø±ÙŠÙ†Ø§...",
  "results": [
    {
      "_id": "...",
      "title": "Ø´Ù‚Ø© ÙØ§Ø®Ø±Ø© ÙÙŠ Ø¯Ø¨ÙŠ Ù…Ø§Ø±ÙŠÙ†Ø§",
      "price": 1850000,
      "location": { "city": "Dubai", "area": "Dubai Marina" },
      "bedrooms": 2,
      "score": 0.92
    }
  ],
  "followUpQuestion": "Ù‡Ù„ ØªÙØ¶Ù„ Ø´Ù‚Ø© Ø¨Ø¥Ø·Ù„Ø§Ù„Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø­Ø±ØŸ",
  "meta": {
    "resultsCount": 3,
    "timestamp": "2025-11-17T..."
  }
}
```

---

### 2. Generate Embedding for Single Property

**POST** `/api/ai/generate-embedding/:propertyId`

**Headers:**
```
Authorization: Bearer <your-jwt-token>
```

**Response:**
```json
{
  "success": true,
  "message": "Embedding generated successfully",
  "property": {
    "id": "...",
    "title": "Luxury Apartment",
    "hasEmbedding": true
  }
}
```

---

### 3. Generate Embeddings for All Properties

**POST** `/api/ai/generate-all-embeddings`

**Headers:**
```
Authorization: Bearer <your-jwt-token>
```

**Response:**
```json
{
  "success": true,
  "message": "Successfully generated embeddings for 47 properties",
  "count": 47
}
```

---

### 4. Test Vector Search

**POST** `/api/ai/test-search`

**Body:**
```json
{
  "query": "luxury villa with pool"
}
```

**Response:**
```json
{
  "success": true,
  "results": [...],
  "count": 5
}
```

---

## ğŸ”„ Usage Workflow

### Initial Setup (One Time)

```bash
# 1. Generate embeddings for all existing properties
POST /api/ai/generate-all-embeddings
```

### For New Properties

Whenever a new property is created, generate its embedding:

```javascript
const { generatePropertyEmbedding } = require("./ai/services/embeddings.service");

// After creating a property
await generatePropertyEmbedding(newProperty._id);
```

Or add a hook in your property model:

```javascript
propertySchema.post("save", async function (doc) {
  if (!doc.embedding) {
    const { generatePropertyEmbedding } = require("../ai/services/embeddings.service");
    await generatePropertyEmbedding(doc._id);
  }
});
```

---

## ğŸ§ª Testing

### Test 1: Generate Embeddings

```bash
curl -X POST http://localhost:5000/api/ai/generate-all-embeddings \
  -H "Authorization: Bearer YOUR_TOKEN"
```

### Test 2: AI Query

```bash
curl -X POST http://localhost:5000/api/ai/query \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Ø£Ø±ÙŠØ¯ Ø´Ù‚Ø© ÙÙŠ Ø¯Ø¨ÙŠ Ø¨Ø³Ø¹Ø± Ù…Ø¹Ù‚ÙˆÙ„"
  }'
```

---

## ğŸ¯ Features

âœ… **OpenAI Embeddings** - Uses `text-embedding-3-large` (3072 dimensions)  
âœ… **Vector Search** - MongoDB Atlas vector search with filters  
âœ… **OpenAI Chat Integration** - Natural Arabic responses (default gpt-4o-mini)  
âœ… **RAG Architecture** - Retrieves relevant data before generating answers  
âœ… **No Hallucination** - Uses only retrieved property data  
âœ… **Production Ready** - Error handling, logging, validation  
âœ… **Scalable** - Supports batch embedding generation  

---

## ğŸ“Š Performance Optimization

### 1. Batch Embedding Generation

For large datasets, process in batches:

```javascript
const properties = await Property.find({ embedding: null }).limit(100);
for (const prop of properties) {
  await generatePropertyEmbedding(prop._id);
  await new Promise(resolve => setTimeout(resolve, 500)); // Rate limiting
}
```

### 2. Cache Embeddings

Embeddings are stored in MongoDB and only regenerated when property data changes.

### 3. Adjust Vector Search Parameters

```javascript
// In vector-search.service.js
numCandidates: 100, // Increase for better accuracy (slower)
limit: 5,           // Number of results to return
```

---

## ğŸ” Security

- All AI endpoints require authentication (`authMiddleware`)
- Admin-only routes for embedding generation
- Input validation on all requests
- Error messages sanitized in production

---

## ğŸ› Troubleshooting

### Error: "Vector search index not found"

**Solution:** Wait 2-5 minutes after creating the index, or check the index name matches `property_vector_index`

### Error: "OpenAI API key invalid"

**Solution:** Check your `.env` file and ensure `OPENAI_API_KEY` is set correctly

### No results from vector search

**Solution:** Ensure embeddings are generated for your properties:
```bash
POST /api/ai/generate-all-embeddings
```

### Slow response times

**Solution:** 
- Reduce `numCandidates` in vector search
- Set `OPENAI_COMPLETION_MODEL=gpt-3.5-turbo` if you need faster/cheaper runs
- Implement caching for common queries

---

## ğŸ“ Example Integration in Frontend

```javascript
// React component example
const searchProperties = async (query) => {
  const response = await axios.post('/api/ai/query', {
    query: query,
    filters: {
      maxPrice: 2000000,
      type: 'apartment'
    }
  }, {
    headers: {
      Authorization: `Bearer ${token}`
    }
  });

  console.log(response.data.answer);      // AI response
  console.log(response.data.results);     // Matching properties
  console.log(response.data.followUpQuestion); // Next question
};
```

---

## ğŸš¦ Rate Limits

OpenAI API has rate limits. For production:

- Implement request queuing
- Add rate limiting middleware
- Cache common queries
- Use Redis for session management

---

## ğŸ’° Cost Estimation

### Embeddings Cost (text-embedding-3-large)
- ~$0.13 per 1M tokens
- Average property: ~200 tokens
- 1000 properties: ~$0.026

### OpenAI Chat Cost (default gpt-4o-mini)
- Check [OpenAI pricing](https://openai.com/pricing) for the latest per-token rates
- Average query cost depends on tokens returned (typically a few cents)

**Tip:** Switch `OPENAI_COMPLETION_MODEL` to `gpt-3.5-turbo` or `gpt-4o-mini-high` to balance cost vs. quality.

---

## ğŸ“ Support

For issues or questions, check:
1. MongoDB Atlas index status
2. OpenAI API key validity
3. Server logs for detailed errors
4. This README for setup steps

---

**ğŸ‰ Your AI module is now ready to use!**
